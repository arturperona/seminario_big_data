{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"res/viu_logo.png\" width=\"200\"><img src=\"res/datathonlogo.png\" width=\"250\"> <meta charset=\"utf-8\">\n",
    "    <small>©2023 VIU - Master Universitario en Big data y Data Science</small>\n",
    "                                                     \n",
    "<img src=\"res/banner.png\" width=\"2000\">\n",
    " \n",
    "# Cómo afrontar un proyecto de competición de ciencia de datos: el caso del Datathon Cajamar 2022\n",
    "\n",
    "<br>\n",
    " Arturo Martínez Perona, Data Analyst en VIU - Universidad Internacional de Valencia\n",
    "<br>\n",
    " José Ramón Casero Fuentes, Data Scientist en Accenture\n",
    "<br>\n",
    "<img src=\"res/winners.jpeg\" width=\"450\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicializando el proyecto\n",
    "\n",
    "A la hora de inicializar un proyecto de datos, existen múltiples pasos a tener en cuenta. Esto puede encararse en dos planos diferentes, uno de ellos podría ser considerado como el físico, es decir, todo aquel que se dedique al mantenimiento y desarrollo del código, y el otro podría llamarse como __no físico__, o aquel más orientado a la estrategia. Este último pertenecería más especialmente a lo que conocemos como metodologías de proyectos.\n",
    "\n",
    "Por lo que respecta a ese plano __físico__, y especialmente si este proyecto incluye varias personas es buena idea, utilizar un sistema de control de versiones, como Git.\n",
    "Un sistema de control de versiones (VCS) es un conjunto de herramientas que rastrean la historia de una serie de ficheros. Esto significa que el sistema es capaz de guardar el estado de los ficheros en un momento determinado, para después continuar con su edición y almacenar también ese estado. Almacenar el estado es similar a crear una copia de seguridad del directorio de trabajo. Cuando se usa Git, esto almacenamiento del estado se conoce como hacer un commit.\n",
    "\n",
    "Cuando se hace un commit en Git, se añade un mensaje para ese commit que explique los cambios. Git puede mostrar la historia de todos los commits y sus mensajes asociados. Esto permite poder navegar con facilidad sobre los cambios realizados, así como informar a los compañeros acerca del historial, permitiendo encontrar más fácilmente errores, o solucionarlos volviendo a un estado anterior.\n",
    "\n",
    "\n",
    "Para crear las bases del proyecto se puede construir una típica estructura de proyecto de python para git\n",
    "\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ bash\n",
    "└── datathon\n",
    "    ├── docs\n",
    "    ├── README.md\n",
    "    ├── .gitignore\n",
    "    ├── data\n",
    "    ├── models\n",
    "    ├── res\n",
    "    ├── results\n",
    "    └── scripts\n",
    "        ├── eda.ipynb\n",
    "        ├── train.py\n",
    "        └── test.py\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "El fichero *`eda.ipynb`* es un notebook de python donde se realiza un análisis exploratorio de datos, permitiendo ejecutar código y visualizar fácilmente, al ser una fase más de compresión y exploración, los notebooks son realmente útiles.\n",
    "\n",
    "Los ficheros *`train.py`* y *`test.py`* son un ejemplo posible para lanzarse ya a la ejecución del entrenamiento de un modelo basándose en la información adquirida durante la fase de exploración. \n",
    "\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ python linenumbers\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entornos virtuales\n",
    "\n",
    "Otra buena opción a la hora de trabajar en un proyecto es la utilización de un entorno virtual. Cuando se trabaja en un proyecto, especialmente si es grande, y participan diferentes actores, esto puede llevar a problemas de integridad de versiones de librerías o incluso de la misma versión de python. Pongámos un ejemplo:\n",
    "\n",
    "En vuestro grupo sois 3 personas, y vais a utilizar la librería statsmodels, sin embargo, uno de vosotros está utilizando esa librería para un proyecto personal, o para un trabajo de una asignatura, y en concreto está utilizando la versión 2.0.1, porque necesita una funcionalidad específica de esa versión, de modo que la tiene instalada en su sistema. Ahora bien, los demás han estado investigando y han encontrado un método para el análisis de una serie temporal que utiliza esa librería, pero que necesita la última versión, esto podría generar incompatibilidad con vuestro compañero.\n",
    "\n",
    "El objetivo principal de un entorno virtual es crear un entorno aislado para los proyectos de Python. Cada proyecto puede tener sus propias librerias y dependencias, sin importar las dependencias que tengan otros proyectos. No hay límite de entornos que se pueden tener, puesto que son simplemente directorios con unos cuantos scripts, y se gestionan fácilmente usando *virtualenv*.\n",
    "\n",
    "Para instalar *virtualenv* hay que hacerlo a través del instalador de paquetes de Python *pip*, desde la línea de comandos.\n",
    "\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Bash\n",
    "arturo@arturo-GS40-6QE-Phantom:/media/arturo/Baldr/seminario_big_data$ pip install virtualenv\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Se suele usar la convención de crear los entornos virtuales dentro de cada proyecto en el directorio raíz de los mismos, en una carpeta que se suele llamar `.venv`. De tal forma que dentro de cada proyecto ya van contenidos tanto la versión de Python requerida como los paquetes de los que se dependen.\n",
    "\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Bash\n",
    "arturo@arturo-GS40-6QE-Phantom:/media/arturo/Baldr/seminario_big_data$ mkdir Project\n",
    "arturo@arturo-GS40-6QE-Phantom:/media/arturo/Baldr/seminario_big_data$ cd Project\n",
    "arturo@arturo-GS40-6QE-Phantom:/media/arturo/Baldr/seminario_big_data$ virtualenv --python=/usr/bin/python3.10 .venv\n",
    "\n",
    "\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "<img src=\"res/virtualenv_ex.png\" width=\"800\"> \n",
    "<br>\n",
    "<small>Localización del entorno virtual y su contenido </small>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodología\n",
    "\n",
    "Por lo que respecta al plano estratégico del proyecto, existen diferentes modelos metodológicos que se pueden implementar a vuestro proyecto. Un ejemplo es *[CRISP-DM](https://www.ibm.com/docs/it/spss-modeler/saas?topic=dm-crisp-help-overview)*, el cual nosotros utilizamos de una manera más o menos flexible.\n",
    "\n",
    "<img src=\"res/metodologia_ex.png\" width=\"800\"><img src=\"res/cripsdm.png\" width=\"450\">\n",
    "<br>\n",
    "<small>Ejemplo esquemático del proyecto para Water Consumption de la competición en 2022 adaptado de CRISP-DM(IBM)</small>\n",
    "\n",
    "\n",
    "\n",
    "La razón principal para utilizar una metodología es precisamente planificar diferentes fases e hitos para el proyecto, esto permite dividir las tareas de forma eficiente e ir completando una serie de pasos, que en general van desde una fase de minería de datos hasta la puesta en marcha del modelo.\n",
    "\n",
    "## Entendiendo el problema\n",
    "\n",
    "En el caso del esquema anterior, puede verse que el primer paso es una fase de entendimiento de negocio o de los datos. Si bien se puede sentir la tentación de ponernos manos a la obra y explorar rápidamente los datos, buscar outliers, valores negativos o no procedentes, y empezar a aplicar todo tipo de algoritmos y funciones sobre los mismo. Realmente la parte más importante es precisamente entender que es lo que tenemos delante, ya que en el momento en que vayamos explorar los datos, solo así entenderemos cual es la necesidad.\n",
    "\n",
    "Para el caso del Datathon Water footprint 2022, el objetivo era realizar una predicción de demanda de consumo de agua.\n",
    "La estimación correcta de la demanda de agua potable representa una condición indispensable para\n",
    "la planificación, diseño y operación eficiente y sostenible de todos los elementos que conforman los\n",
    "sistemas de captación, transporte y suministro de agua potable. Esta demanda está sujeta a\n",
    "variaciones interanuales, estacionales, semanales, diarias e incluso horarias, muy significativas y que\n",
    "dependen de múltiples factores como son los ciclos de actividad económica, la meteorología, las\n",
    "situaciones de crisis sanitaria, los cambios en los bloques tarifarios, etc.\n",
    "\n",
    "Por tanto se establece como objetivo el crear un modelo de predicción de consumo de agua para\n",
    "realizar estimaciones a futuro, a partir de un conjunto de datos histórico.\n",
    "\n",
    "En principio, **es esperable que entre una gran cantidad de contadores estos no se comporten todos\n",
    "igual**. Esto es debido a que algunos pueden ser industriales, otros de hogares partículares, otros de\n",
    "casas de veraneo, etc..\n",
    "\n",
    "<img src=\"res/clusters.png\" width=\"800\">\n",
    "<br>\n",
    "<small>Diferentes posibles naturalezas de los contadores de agua</small>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando los datos\n",
    "\n",
    "Una vez planificado el trabajo, es hora de observar cuales son los datos de entrada que se tienen:\n",
    "\n",
    "**Variables**\n",
    " \n",
    "\n",
    "*   ID: Identificador del Contador que registra la medida de lectura.\n",
    "*   SAMPLETIME: Fecha y hora del consumo en formato UTC. Momento en el que se\n",
    "produce el mensaje o el contador ha emitido el registro.\n",
    "*   READINGINTEGER: Medida registrada por el contador en litros. Parte entera.\n",
    "*   READINGTHOUSANDTH: Medida registrada por el contador en litros. Parte decimal.\n",
    "*   DELTAINTEGER: Consumo calculado en litros a partir de la medida registrada por el contador. Parte entera.\n",
    "*   DELTATHOUSANDTH: Consumo calculado en litros a partir de la medida registrada por el contador. Parte decimal.\n",
    "\n",
    "\n",
    "Los ID están ordenados de forma ascendente pero no son correlativos\n",
    "\n",
    "**Formato y estructura**\n",
    "Este dataset tiene extensión txt con la siguiente estructura y formato:\n",
    "• Nombres de variables: incluidos en la cabecera\n",
    "• Separador: \"|\"\n",
    "• Codificación: UTF-8\n",
    "Sin nombre de fila.\n",
    "\n",
    "### Visualización\n",
    "\n",
    "Uno de los primeros pasos para encarar el proyecto es probar a visualizar los datos, con esto podemos rapidamente ser conscientes del comportamiento general de los datos, ver patrones, posible estacionalidad, etc...\n",
    "\n",
    "A la hora de realizar este paso existen múltiples caminos a seguir:\n",
    "* Weka\n",
    "* Jupyter\n",
    "* R\n",
    "* Tableau\n",
    "* Power BI\n",
    "\n",
    "\n",
    "Power BI es una herramienta muy interesante a la hora de construir rápidamente visualizaciones y explorar los datos. Ya que os permite poder realizar análisis y cálculos de manera bastante sencilla y es amigable a la hora de filtrar datos, hacer agregaciones, segmentarlos, etc...\n",
    "\n",
    "Además, los informes de Power BI pueden ser embebidos más adelante incluso en un notebook de jupyter, tal y como os introduzco a continuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from powerbiclient import Report\n",
    "from io import StringIO\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from powerbiclient.authentication import DeviceCodeLoginAuthentication\n",
    "\n",
    "device_auth = DeviceCodeLoginAuthentication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_id = '69200dca-dd49-4f79-b610-13bc461575ea'\n",
    "group_id = '42292854-eaf4-4c0f-8f72-b1c035cea3f2'\n",
    "report = Report(group_id=group_id, report_id=report_id, auth=device_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaded_callback(event_details):\n",
    "    print('Report is loaded')\n",
    "\n",
    "report.on('loaded', loaded_callback)\n",
    "def rendered_callback(event_details):\n",
    "    print('Report is rendered')\n",
    "\n",
    "report.on('rendered', rendered_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.set_size(800, 1100)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajando los datos\n",
    "\n",
    "En paralelo a esa visualización de datos, es posible que nos hayamos ya dado cuenta de que los datos requieren un pre-procesado para poder trabajar con ellos a mayor nivel. Esto puede suponer realizar agregaciones de datos, seleccionar un subset de los mismos, comprobar valores vacíos, etc...\n",
    "\n",
    "Durante el proceso de exploración y visualizando los datos inicialmente determinamos que se tenían 2747 contadores de agua diferentes siendo la fecha mínima el 2019-02-01 y la fecha máxima el 2020-01-31. La gran mayoría de los contadores registraron medidas durante el periodo completo, en este caso más de 2000 IDs registraron los 365 días, por lo que se puede comprobar que la serie de datos está bastante completa, pero es destacable también algunos grupos de IDs que registrar incluso menos de 100 días de datos.\n",
    "\n",
    "Con el objetivo de estudiar el comportamiento de la serie de la manera más sencilla, en primer lugar se decidió trabajar con un grupo de 100 IDs, reduciendo así el tamaño del conjunto. Puesto que el conjunto de datos no tiene muchas características, debemos centrarnos en los aspectos principales de una **serie temporal univariante**, tales como los ciclos, la tendencia y la estacionalidad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro caso previamente ya hemos hecho una agregación de los datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-10</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    datetime  consumption\n",
       "0    0  2019-02-01          243\n",
       "1    0  2019-02-02          236\n",
       "2    0  2019-02-03          335\n",
       "3    0  2019-02-04          252\n",
       "4    0  2019-02-05          220\n",
       "5    0  2019-02-06          276\n",
       "6    0  2019-02-07          277\n",
       "7    0  2019-02-08          193\n",
       "8    0  2019-02-09          262\n",
       "9    0  2019-02-10          315\n",
       "10   0  2019-02-11          224\n",
       "11   0  2019-02-12          337\n",
       "12   0  2019-02-13          219\n",
       "13   0  2019-02-14          264\n",
       "14   0  2019-02-15          384"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_consumptions = pd.read_csv('../src/data/water_consumption_complete.csv', sep=\",\")\n",
    "water_consumptions.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    datetime  consumption\n",
       "0   0  2019-02-01          243\n",
       "1   0  2019-02-02          236\n",
       "2   0  2019-02-03          335\n",
       "3   0  2019-02-04          252\n",
       "4   0  2019-02-05          220"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_consumptions_100 = water_consumptions[water_consumptions['id'] <= 100]\n",
    "water_consumptions_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35594, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_consumptions_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100}\n"
     ]
    }
   ],
   "source": [
    "print(set(water_consumptions_100['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting when the default backend \"matplotlib\" is selected.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m water_consumptions_100\u001b[39m.\u001b[39;49mplot()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\plotting\\_core.py:921\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 921\u001b[0m     plot_backend \u001b[39m=\u001b[39m _get_plot_backend(kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mbackend\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[0;32m    923\u001b[0m     x, y, kind, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_call_args(\n\u001b[0;32m    924\u001b[0m         plot_backend\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent, args, kwargs\n\u001b[0;32m    925\u001b[0m     )\n\u001b[0;32m    927\u001b[0m     kind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kind_aliases\u001b[39m.\u001b[39mget(kind, kind)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\plotting\\_core.py:1908\u001b[0m, in \u001b[0;36m_get_plot_backend\u001b[1;34m(backend)\u001b[0m\n\u001b[0;32m   1905\u001b[0m \u001b[39mif\u001b[39;00m backend_str \u001b[39min\u001b[39;00m _backends:\n\u001b[0;32m   1906\u001b[0m     \u001b[39mreturn\u001b[39;00m _backends[backend_str]\n\u001b[1;32m-> 1908\u001b[0m module \u001b[39m=\u001b[39m _load_backend(backend_str)\n\u001b[0;32m   1909\u001b[0m _backends[backend_str] \u001b[39m=\u001b[39m module\n\u001b[0;32m   1910\u001b[0m \u001b[39mreturn\u001b[39;00m module\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\plotting\\_core.py:1839\u001b[0m, in \u001b[0;36m_load_backend\u001b[1;34m(backend)\u001b[0m\n\u001b[0;32m   1837\u001b[0m         module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39mpandas.plotting._matplotlib\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1838\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m-> 1839\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   1840\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmatplotlib is required for plotting when the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1841\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mdefault backend \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m is selected.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1842\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m   1843\u001b[0m     \u001b[39mreturn\u001b[39;00m module\n\u001b[0;32m   1845\u001b[0m found_backend \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: matplotlib is required for plotting when the default backend \"matplotlib\" is selected."
     ]
    }
   ],
   "source": [
    "water_consumptions_100.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "water_consumptions_100.index = pd.to_datetime(water_consumptions_100.index)\n",
    "\n",
    "result_mul = seasonal_decompose(water_consumptions_100['consumption'], model='multiplicative', extrapolate_trend='freq')\n",
    "result_add = seasonal_decompose(water_consumptions_100['consumption'], model='additive', extrapolate_trend='freq')\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.rcParams.update({'figure.figsize': (10,10)})\n",
    "result_mul.plot().suptitle('Multiplicative Decompose', fontsize=22)\n",
    "result_add.plot().suptitle('Additive Decompose', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "# Draw Plot\n",
    "plt.rcParams.update({'figure.figsize':(9,5), 'figure.dpi':120})\n",
    "autocorrelation_plot(water_consumptions_100.consumption.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(16,3), dpi= 100)\n",
    "plot_acf(water_consumptions_100.consumption.tolist(), lags=10, ax=axes[0])\n",
    "plot_pacf(water_consumptions_100.consumption.tolist(), lags=10, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División Train - Test\n",
    "\n",
    "Tal y como hemos ido comprobando, por las características de los datos, estamos hablando de una serie temporal. Y esto quiere decir que, en cierta manera los datos son continuos, y que a la hora de predecir, estamos haciendo un forecasting de los siguentes n valores.\n",
    "\n",
    "Por ello, se debe tener cuidado al seleccionar una división entre train-test, ya que estas deben presentar una continuidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "first_test_date = datetime(2020, 1, 1)\n",
    "train_general = water_consumptions_100[water_consumptions_100.index < first_test_date]\n",
    "test_general = water_consumptions_100[water_consumptions_100.index >= first_test_date]\n",
    "print(len(train_general))\n",
    "print(len(test_general))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
