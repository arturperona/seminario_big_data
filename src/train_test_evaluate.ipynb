{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skforecast in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.57.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from skforecast) (4.64.1)\n",
      "Requirement already satisfied: scikit-optimize==0.9.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from skforecast) (0.9.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.20 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from skforecast) (1.23.3)\n",
      "Requirement already satisfied: scikit-learn<1.2,>=1.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from skforecast) (1.1.2)\n",
      "Requirement already satisfied: optuna<3.1,>=2.10.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from skforecast) (3.0.5)\n",
      "Requirement already satisfied: joblib<1.3.0,>=1.1.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from skforecast) (1.2.0)\n",
      "Requirement already satisfied: pandas<1.6,>=1.2 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from skforecast) (1.5.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from scikit-optimize==0.9.0->skforecast) (1.8.1)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from scikit-optimize==0.9.0->skforecast) (21.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from scikit-learn<1.2,>=1.0->skforecast) (3.1.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (1.9.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (2.0.1)\n",
      "Requirement already satisfied: PyYAML in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (4.12.0)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (0.9.1)\n",
      "Requirement already satisfied: colorlog in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (21.3)\n",
      "Requirement already satisfied: cliff in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from optuna<3.1,>=2.10.0->skforecast) (4.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from pandas<1.6,>=1.2->skforecast) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from pandas<1.6,>=1.2->skforecast) (2022.2.1)\n",
      "Requirement already satisfied: Mako in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna<3.1,>=2.10.0->skforecast) (1.2.4)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna<3.1,>=2.10.0->skforecast) (5.10.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna<3.1,>=2.10.0->skforecast) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna<3.1,>=2.10.0->skforecast) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from importlib-metadata<5.0.0->optuna<3.1,>=2.10.0->skforecast) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from packaging>=20.0->optuna<3.1,>=2.10.0->skforecast) (3.0.9)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from cliff->optuna<3.1,>=2.10.0->skforecast) (3.6.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from cliff->optuna<3.1,>=2.10.0->skforecast) (0.5.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from cliff->optuna<3.1,>=2.10.0->skforecast) (4.1.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from cliff->optuna<3.1,>=2.10.0->skforecast) (2.4.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas<1.6,>=1.2->skforecast) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna<3.1,>=2.10.0->skforecast) (2.1.1)\n",
      "Requirement already satisfied: wcwidth in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from PrettyTable>=0.7.2->cliff->optuna<3.1,>=2.10.0->skforecast) (0.2.5)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from stevedore>=2.0.1->cliff->optuna<3.1,>=2.10.0->skforecast) (5.11.1)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.1,>=2.10.0->skforecast) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.1,>=2.10.0->skforecast) (22.2.0)\n",
      "Requirement already satisfied: statsmodels in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (0.13.5)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from statsmodels) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.17; python_version != \"3.10\" or platform_system != \"Windows\" or platform_python_implementation == \"PyPy\" in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from statsmodels) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3; (python_version > \"3.9\" or platform_system != \"Windows\" or platform_machine != \"x86\") and python_version < \"3.12\" in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from statsmodels) (1.8.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from packaging>=21.3->statsmodels) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from pandas>=0.25->statsmodels) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: six in /home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install skforecast\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema final vs problema local\n",
    "Hay que tener en cuenta en este tipo de concursos la diferencia entre el problema final y el problema local, o subproblema, que utilizamos para simular que tenemos acceso al problema completo.\n",
    "\n",
    "**Problema final**: predicción del consumo de agua por días de diferentes contadores distribuidos en la Comunidad Valencia. Problema para evaluarlo: solo tenemos acceso a dos evaluaciones por cada entrega y el número de entregas es reducida.\n",
    "**Problema local**: vamos a coger un subconjunto de datos reducido para poder evaluar el desempeño de distintas combinaciones de algoritmos y procesamientos que queramos probar, evaluar su desempeño y finalmente, elegir los mejores para aplicarlos al problema final. Es interesante tque este problema local sea lo más similar posible al problema final\n",
    "\n",
    "Tengamos en cuenta que pueden darse situaciones en las que se nos den resultados inesperados, por ejemplo que un algoritmo que ha desempeñado peor en nuestro problema local, nos de un mejor resultado que en la entrega final. A esto lo podemos llamar **error de correlación**, se puede dar porque al final el problema local no es igual al problema final aunque intentemos simularlo, debido puede ser interesante que en una primera instancia hagamos entregas de cosas muy diferentes, pero que consideemos que pueden ser interesantes, para validar que hemos seleccionado bien el subproblema o por donde puede estar más claro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              int64\n",
      "datetime       object\n",
      "consumption     int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    datetime  consumption\n",
       "0   0  2019-02-01          243\n",
       "1   0  2019-02-02          236\n",
       "2   0  2019-02-03          335\n",
       "3   0  2019-02-04          252\n",
       "4   0  2019-02-05          220"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_consumptions = pd.read_csv('./data/water_consumptions_100.csv')\n",
    "print(water_consumptions.dtypes)\n",
    "water_consumptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      int64\n",
       "datetime       datetime64[ns]\n",
       "consumption             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_consumptions['datetime'] = water_consumptions['datetime'].apply(pd.to_datetime)\n",
    "water_consumptions.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos\n",
    "\n",
    "En esta primera etapa, vamos a preparar los datos para que puedan ser usados fácilmente para preprocesarlos, ingeniería de características, entrenamiento, predicción y evaluación. Esta etapa es común tanto para el problema final como el local, y es importante dedicarle algo de tiempo porque nos va a facilitar el resto de etapas.\n",
    "\n",
    "En est caso como ya tenemos los dataframe con las series temporales para entrenar y predecir, en este apartado hemos hecho algunas transformaciones para obtener un diccionario de id-serie_temporal que nos va a ser útil a la hora de crear los clusters más adelante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of series: 101\n",
      "Number of complete series:  81\n"
     ]
    }
   ],
   "source": [
    "N_DAYS_YEAR = 365\n",
    "\n",
    "id_length = water_consumptions.groupby(['id']).size()\n",
    "print('Number of series:', len(id_length))\n",
    "complete_series_ids = id_length[id_length == N_DAYS_YEAR]\n",
    "complete_series_ids = complete_series_ids.to_frame().reset_index()\n",
    "print('Number of complete series: ', len(complete_series_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35589</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35590</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35591</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35592</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35593</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29565 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   datetime  consumption\n",
       "0        0 2019-02-01          243\n",
       "1        0 2019-02-02          236\n",
       "2        0 2019-02-03          335\n",
       "3        0 2019-02-04          252\n",
       "4        0 2019-02-05          220\n",
       "...    ...        ...          ...\n",
       "35589  100 2020-01-27          471\n",
       "35590  100 2020-01-28          445\n",
       "35591  100 2020-01-29          720\n",
       "35592  100 2020-01-30          402\n",
       "35593  100 2020-01-31          414\n",
       "\n",
       "[29565 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_series_df = water_consumptions[water_consumptions['id'].isin(complete_series_ids['id'])]\n",
    "complete_series_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption_series = dict()\n",
    "\n",
    "for id_serie in set(complete_series_df['id']):\n",
    "  id_df = complete_series_df[complete_series_df['id'] == id_serie]\n",
    "  date_consumption_df = id_df.loc[:,[\"datetime\",\"consumption\"]]\n",
    "  date_consumption_df.set_index(\"datetime\",inplace=True)\n",
    "  date_consumption_df.sort_index(inplace=True)\n",
    "  consumption_series[id_serie] = date_consumption_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "La clusterización es un algoritmo que es sensible a la magnitud de las características, con lo cual, decidimos aplicar un preprocesamiento a las series temporales en forma de estandarización en nuestro caso. Este tipo de preprocesamiento, lo aplicaremos más adelanta también en las etapas de entrenamiento y predicción, para las variables de entrada a los modelos.\n",
    "\n",
    "El preprocesamiento de los datos puede ser tan importante, o incluso más, que el propio modelo o algoritmo. Es muy importante saber con el tipo de modelo que estamos trabajando y qué preprocesamiento es necesario para que funcione de forma normal, o para mejorar su desempeño. \n",
    "Algunos de los métodos más fáciles de utilizar, debido a que se usan comúnmente son:\n",
    "- Escalado:\n",
    "- Normalización:\n",
    "- Estandarización:\n",
    "\n",
    "Un preprocesamiento básico puede darnos una gran sorpresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.72417048e-01, -4.37922043e-01,  4.88505743e-01, -2.88196340e-01,\n",
       "       -5.87647745e-01, -6.36077857e-02, -5.42499293e-02, -8.40309869e-01,\n",
       "       -1.94617776e-01,  3.01348615e-01, -5.50216320e-01,  5.07221456e-01,\n",
       "       -5.97005602e-01, -1.75902063e-01,  9.47040708e-01, -3.55342164e-02,\n",
       "        5.63368595e-01,  3.48137897e-01,  1.19034498e+00, -2.22691345e-01,\n",
       "        2.82632902e-01,  9.18967139e-01, -5.68932033e-01,  6.75662872e-01,\n",
       "        9.37682852e-01, -3.25627766e-01,  2.91990758e-01, -9.61962002e-01,\n",
       "       -6.99942023e-01, -4.94069181e-01,  6.66305015e-01,  3.57495753e-01,\n",
       "        3.38780040e-01,  1.89054338e-01, -3.72417048e-01, -1.38306554e+00,\n",
       "       -1.57186350e-01,  1.31199711e+00,  2.45365559e+00, -5.87647745e-01,\n",
       "       -6.90584166e-01,  1.80796350e+00,  3.85569323e-01,  2.99707785e-02,\n",
       "       -5.40858463e-01, -6.43794884e-01,  1.15291355e+00,  1.12550657e-02,\n",
       "        9.09609282e-01, -8.77741295e-01,  9.54757735e-02,  9.47040708e-01,\n",
       "       -5.12784894e-01, -1.06489842e+00,  3.93286349e-02,  3.76211466e-01,\n",
       "        1.64887994e+00,  1.23549343e-01,  1.08740855e+00,  9.09609282e-01,\n",
       "        2.26485763e-01,  1.07805070e+00,  2.18227776e+00, -4.84711325e-01,\n",
       "        1.45236495e+00,  9.75114277e-01,  2.45201476e-01,  4.32358605e-01,\n",
       "        4.69790030e-01,  3.85569323e-01,  7.41167867e-01, -4.56637755e-01,\n",
       "       -6.62510597e-01,  3.66853610e-01, -7.46064718e-03, -1.73866409e+00,\n",
       "       -4.56637755e-01, -2.64637616e+00, -2.64637616e+00, -2.64637616e+00,\n",
       "       -2.64637616e+00, -2.64637616e+00, -2.64637616e+00,  1.13419784e+00,\n",
       "        7.59883580e-01, -2.69480627e-01, -7.65447017e-01,  2.99707785e-02,\n",
       "       -1.19754924e-01, -1.30820269e+00, -6.36077857e-02, -5.03427038e-01,\n",
       "        1.79696481e-01,  6.38231446e-01,  3.57495753e-01, -1.38470637e-01,\n",
       "       -9.90035572e-01,  1.51622912e-01,  5.16579313e-01,  4.86864914e-02,\n",
       "        1.68631137e+00, -5.42499293e-02,  4.60432174e-01,  3.48137897e-01,\n",
       "        1.19034498e+00,  4.69790030e-01, -5.50216320e-01,  5.72726451e-01,\n",
       "        9.28324995e-01,  7.87957149e-01,  8.34746431e-01, -1.42985482e+00,\n",
       "       -1.39242340e+00, -1.45792839e+00,  4.97863600e-01,  1.18098712e+00,\n",
       "       -6.99942023e-01,  3.38780040e-01, -1.30820269e+00, -1.38470637e-01,\n",
       "       -3.72417048e-01,  1.60980768e-01,  4.51074318e-01, -2.13333488e-01,\n",
       "        2.20099347e+00, -1.57186350e-01, -1.26141341e+00, -6.06363458e-01,\n",
       "        2.49108702e+00, -1.38470637e-01, -3.91132761e-01,  1.12483998e+00,\n",
       "       -3.55342164e-02, -2.60122771e-01, -1.20526627e+00,  1.70338625e-01,\n",
       "       -6.81226310e-01, -1.47664411e+00, -1.67315909e+00,  9.37682852e-01,\n",
       "       -7.93520587e-01, -5.03427038e-01,  2.27585632e+00, -1.18655056e+00,\n",
       "        1.75181636e+00,  1.70502708e+00,  9.65756421e-01,  7.67600606e-02,\n",
       "        1.56465923e+00,  9.84472134e-01,  5.44652882e-01, -6.36077857e-02,\n",
       "       -9.24530577e-01, -1.05554057e+00,  6.66305015e-01,  1.65823780e+00,\n",
       "        6.38231446e-01, -5.78289889e-01,  2.39750845e+00, -1.24269770e+00,\n",
       "       -9.80677715e-01,  9.84472134e-01, -3.53701335e-01,  2.47237131e+00,\n",
       "       -5.03427038e-01,  2.46301345e+00,  1.14191486e-01, -2.97554196e-01,\n",
       "       -8.30952012e-01,  9.37682852e-01,  6.19515733e-01, -6.62510597e-01,\n",
       "       -1.01039211e-01,  1.18098712e+00, -3.06912053e-01,  3.01348615e-01,\n",
       "        2.82632902e-01,  7.50525723e-01, -3.16269909e-01, -1.01810914e+00,\n",
       "        1.01254570e+00, -1.01039211e-01,  8.61179171e-02,  4.41716461e-01,\n",
       "       -5.68932033e-01, -5.03427038e-01, -1.75902063e-01,  1.03126142e+00,\n",
       "        1.42265056e-01,  1.34007068e+00, -1.15847699e+00,  5.44652882e-01,\n",
       "        1.26520783e+00, -1.57186350e-01, -6.15721315e-01,  2.21035133e+00,\n",
       "        7.87957149e-01, -2.03975632e-01, -7.46731305e-01, -2.64637616e+00,\n",
       "       -2.64637616e+00, -2.64637616e+00, -2.64637616e+00, -2.64637616e+00,\n",
       "       -2.64637616e+00, -2.64637616e+00, -2.64637616e+00, -2.64637616e+00,\n",
       "       -2.64637616e+00, -4.65995612e-01,  1.98412194e-01, -1.86031622e+00,\n",
       "       -2.78838483e-01,  3.06191626e+00,  9.00251426e-01,  9.93829990e-01,\n",
       "       -9.16813550e-02,  3.93286349e-02,  1.07805070e+00,  7.59883580e-01,\n",
       "       -1.66544206e-01, -7.56089161e-01, -2.50764914e-01,  3.93286349e-02,\n",
       "       -3.72417048e-01, -8.23234986e-02,  1.45236495e+00,  4.04285035e-01,\n",
       "       -4.19206330e-01, -1.28948698e+00,  6.19515733e-01,  1.02190356e+00,\n",
       "       -9.61962002e-01,  9.56398564e-01,  6.00800020e-01, -6.62510597e-01,\n",
       "        2.07770051e-01,  1.89054338e-01, -8.68383438e-01, -5.22142750e-01,\n",
       "        5.25937169e-01, -2.32049201e-01,  4.88505743e-01,  2.35843620e-01,\n",
       "       -1.29112781e-01,  3.10706471e-01, -1.68185036e-02,  2.07770051e-01,\n",
       "        2.26649846e+00,  6.19515733e-01,  7.22452154e-01, -3.91132761e-01,\n",
       "       -2.88196340e-01,  5.44652882e-01,  5.91442164e-01,  5.80443478e-02,\n",
       "       -7.74804874e-01, -2.88196340e-01, -5.03427038e-01, -5.31500607e-01,\n",
       "        1.04997713e+00, -8.49667725e-01, -1.01810914e+00,  1.04833630e-01,\n",
       "       -4.00490617e-01,  3.38780040e-01, -3.44343478e-01,  6.28873590e-01,\n",
       "       -7.46731305e-01, -2.41407058e-01, -5.22142750e-01, -2.13333488e-01,\n",
       "       -4.00490617e-01,  2.05126777e+00,  4.51074318e-01,  2.26485763e-01,\n",
       "       -1.01039211e-01,  5.80443478e-02, -6.62510597e-01, -2.22691345e-01,\n",
       "        3.57495753e-01, -1.00875128e+00,  8.44104287e-01,  3.01348615e-01,\n",
       "       -1.75902063e-01, -3.91132761e-01, -2.13333488e-01, -8.23234986e-02,\n",
       "        1.37750210e+00, -1.29112781e-01, -9.99393428e-01, -8.68383438e-01,\n",
       "       -6.71868453e-01,  2.82632902e-01,  4.04285035e-01, -2.22691345e-01,\n",
       "        3.10706471e-01, -2.61763600e-02,  1.29328140e+00, -9.05814864e-01,\n",
       "        9.54757735e-02,  5.25937169e-01, -3.55342164e-02,  3.20064328e-01,\n",
       "       -4.09848473e-01,  1.89720925e-03, -4.37922043e-01,  5.07221456e-01,\n",
       "        6.19515733e-01,  3.01348615e-01, -7.74804874e-01, -4.09848473e-01,\n",
       "       -7.29656421e-02, -6.34437028e-01, -1.43921268e+00,  1.02190356e+00,\n",
       "       -9.43246290e-01,  4.86864914e-02,  3.48137897e-01, -2.32049201e-01,\n",
       "       -6.99942023e-01, -1.22398198e+00,  1.14191486e-01, -4.75353468e-01,\n",
       "       -9.43246290e-01,  6.66305015e-01,  1.09676641e+00, -8.23234986e-02,\n",
       "       -2.32049201e-01,  6.47589302e-01,  6.00800020e-01,  2.54559333e-01,\n",
       "        5.16579313e-01,  4.13642892e-01, -1.47828494e-01, -2.88196340e-01,\n",
       "       -6.99942023e-01,  1.34942853e+00, -7.56089161e-01,  9.65756421e-01,\n",
       "        5.54010738e-01,  7.87957149e-01, -4.19206330e-01, -5.40858463e-01,\n",
       "       -1.17719270e+00, -7.46064718e-03, -1.57022267e+00,  1.58337494e+00,\n",
       "       -6.81226310e-01,  1.89054338e-01, -4.48920729e-02,  1.29328140e+00,\n",
       "       -1.10397068e-01,  2.17127907e-01,  8.61179171e-02,  1.65823780e+00,\n",
       "        4.51074318e-01,  7.97315005e-01,  1.00318785e+00,  1.98412194e-01,\n",
       "       -6.53152740e-01, -4.75353468e-01,  1.12483998e+00,  1.33071282e+00,\n",
       "       -2.60122771e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for index in consumption_series:\n",
    "    scaler = StandardScaler()\n",
    "    consumption_series[index] = scaler.fit_transform(consumption_series[index])\n",
    "    consumption_series[index] = consumption_series[index].reshape(len(consumption_series[index]))\n",
    "    \n",
    "water_series_anonimized = list(consumption_series.values())\n",
    "water_series_anonimized[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterización\n",
    "\n",
    "Tenemos un problema de predicción de consumo de agua por contadores. En este caso se puede dar que distintos contadores tengan comportamiento muy diferente, mientras que otros se puedan generalizar con el mismo patrón. Con lo cual aplicar una clusterización sobre estos contadores es interesante para aplicar distintos modelos a los distintos patrones de comportamiento.\n",
    "\n",
    "En este caso aplicamos la clusterización sobre el problema completo. ¿Porqué es esto? Porque de esta manera los clusters que usemos en nuestro problema local, van a ser los mismos que aquellos que usaremos en el momento de la entrega. En casto contrario, podríamos provocar los mencionados problemas de correlación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OPTIMAL_NUMBER_CLUSTERS = 10\n",
    "SEED = 10\n",
    "\n",
    "k_means = KMeans(n_clusters=OPTIMAL_NUMBER_CLUSTERS, random_state=SEED)\n",
    "k_means.fit(water_series_anonimized)\n",
    "cluster_labels = k_means.labels_\n",
    "\n",
    "y, x, _ = plt.hist(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6,\n",
       " 1: 6,\n",
       " 2: 3,\n",
       " 3: 7,\n",
       " 4: 3,\n",
       " 5: 9,\n",
       " 6: 1,\n",
       " 7: 6,\n",
       " 8: 1,\n",
       " 9: 9,\n",
       " 10: 1,\n",
       " 12: 5,\n",
       " 13: 0,\n",
       " 14: 5,\n",
       " 15: 1,\n",
       " 16: 0,\n",
       " 17: 9,\n",
       " 18: 3,\n",
       " 19: 5,\n",
       " 20: 0,\n",
       " 21: 8,\n",
       " 22: 7,\n",
       " 24: 3,\n",
       " 25: 6,\n",
       " 27: 3,\n",
       " 28: 7,\n",
       " 29: 5,\n",
       " 30: 3,\n",
       " 31: 3,\n",
       " 36: 5,\n",
       " 38: 0,\n",
       " 40: 0,\n",
       " 41: 4,\n",
       " 42: 5,\n",
       " 43: 0,\n",
       " 44: 6,\n",
       " 45: 6,\n",
       " 46: 6,\n",
       " 47: 9,\n",
       " 48: 3,\n",
       " 49: 4,\n",
       " 50: 7,\n",
       " 51: 1,\n",
       " 52: 5,\n",
       " 53: 5,\n",
       " 55: 9,\n",
       " 56: 1,\n",
       " 57: 9,\n",
       " 58: 2,\n",
       " 59: 0,\n",
       " 60: 1,\n",
       " 61: 6,\n",
       " 63: 7,\n",
       " 65: 5,\n",
       " 66: 0,\n",
       " 68: 6,\n",
       " 69: 6,\n",
       " 70: 1,\n",
       " 71: 7,\n",
       " 75: 4,\n",
       " 77: 6,\n",
       " 80: 3,\n",
       " 81: 3,\n",
       " 82: 0,\n",
       " 83: 7,\n",
       " 84: 1,\n",
       " 86: 5,\n",
       " 87: 8,\n",
       " 88: 0,\n",
       " 89: 0,\n",
       " 90: 6,\n",
       " 91: 6,\n",
       " 92: 9,\n",
       " 93: 9,\n",
       " 94: 5,\n",
       " 95: 0,\n",
       " 96: 3,\n",
       " 97: 5,\n",
       " 98: 0,\n",
       " 99: 0,\n",
       " 100: 7}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cluster = dict()\n",
    "for index in consumption_series:\n",
    "    predicted = k_means.predict([consumption_series[index]])\n",
    "    id_cluster[index] = predicted[0]\n",
    "id_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNCOMPLETE_SERIE_CLUSTER = 10\n",
    "\n",
    "def assign_cluster_or_default(id, id_clusters):\n",
    "  if id in id_clusters.keys():\n",
    "    return id_clusters[id]\n",
    "  else:\n",
    "    return UNCOMPLETE_SERIE_CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>consumption</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>243</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>335</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>252</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>220</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35589</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>471</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35590</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>445</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35591</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>720</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35592</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>402</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35593</th>\n",
       "      <td>100</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>414</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   datetime  consumption  cluster\n",
       "0        0 2019-02-01          243        6\n",
       "1        0 2019-02-02          236        6\n",
       "2        0 2019-02-03          335        6\n",
       "3        0 2019-02-04          252        6\n",
       "4        0 2019-02-05          220        6\n",
       "...    ...        ...          ...      ...\n",
       "35589  100 2020-01-27          471        7\n",
       "35590  100 2020-01-28          445        7\n",
       "35591  100 2020-01-29          720        7\n",
       "35592  100 2020-01-30          402        7\n",
       "35593  100 2020-01-31          414        7\n",
       "\n",
       "[35594 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_consumptions['cluster'] = water_consumptions.apply(lambda row: assign_cluster_or_default(row.id, id_cluster), axis = 1)\n",
    "water_consumptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación entrenamiento-predicción (Creación del subproblema)\n",
    "\n",
    "En el problema final, tenemos que predecir dos semanas de consumo diario para cada uno de los contadores; en nuestro subproblema, vamos a hacerlo de la misma manera. Del total de conjunto de datos que tenemos, vamos a seleccionar las últimas dos semanas [2020-01-17 / 2020-01-31] para predicción y evaluación, y el restante [2019-02-01 / 2020-01-16] para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatime range: 2019-02-01 00:00:00 2020-01-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print('Datatime range:', min(water_consumptions['datetime']) ,max(water_consumptions['datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(water_consumptions):\n",
    "    train =  water_consumptions.loc[water_consumptions['datetime'] < datetime(2020, 1, 18)]\n",
    "    test = water_consumptions.loc[water_consumptions['datetime'] >= datetime(2020, 1, 18)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (34193, 4)\n",
      "Test shape: (1401, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(water_consumptions)\n",
    "print('train datatime range:', min(train_df['datetime']) ,max(train_df['datetime']))\n",
    "print('test datatime range:', min(test_df['datetime']) ,max(test_df['datetime']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de los mejores parámetros para el modelo\n",
    "\n",
    "En un problema de predicción, aplicar los parámetros correctos al modelo pueden ser una mejora importante en el comportamiento del mismo para el problema, este este caso para la serie temporal. Es importante aplicar algún tipo de búsqueda sobre la misma para de esta manera aprovecharse de ello. Aquí podemos ver una implementación customizada para el algoritmo SARIMA. En otro problema, podemos utilizar una implementación de Scikit-Learn, Optuna, o cualquier otro algoritmo para el tunning de parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def sarima_grid_search(y, seasonal_period):\n",
    "    p = d = q = range(0, 2)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    seasonal_pdq = [(x[0], x[1], x[2],seasonal_period) for x in list(itertools.product(p, d, q))]\n",
    "    \n",
    "    mini = float('+inf')\n",
    "    \n",
    "    \n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                                order=param,\n",
    "                                                seasonal_order=param_seasonal,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False)\n",
    "                results = mod.fit()\n",
    "                \n",
    "                if results.aic < mini:\n",
    "                    mini = results.aic\n",
    "                    param_mini = param\n",
    "                    param_seasonal_mini = param_seasonal\n",
    "            except:\n",
    "                continue\n",
    "    return {\n",
    "        'order': param_mini,\n",
    "        'seasonal_order': param_seasonal_mini,\n",
    "        'enforce_stationarity': False,\n",
    "        'enforce_invertibility': False\n",
    "    }\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a la magnitud del problema, no podemos hacer una obtención de los mejores parámetros para cada una de las series temporales individuales, es por ello que nos aprovechamos de la clusterización anterior al obtener los mejores parámetros para cada serie en base a su comportamiento clusterizado y mitigando el ruido de cada una de ellas por separado, recordemos que nos interesa el comportamiento general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_grouped_ts(dataset, cluster_id) -> pd.DataFrame:\n",
    "  cluster_series = dataset[dataset['cluster'] == cluster_id]\n",
    "  cluster_series.drop(['id','cluster'], axis = 1, inplace = True)\n",
    "  return cluster_series.groupby('datetime').sum()\n",
    "\n",
    "def grid_search_by_cluster(dataset, seasonal_period=30) -> dict:\n",
    "  best_params_per_cluster = {}\n",
    "  for cluster_id in set(dataset.cluster):\n",
    "    cluster_ts = cluster_grouped_ts(dataset, cluster_id)\n",
    "    best_params_cluster = sarima_grid_search(cluster_ts, seasonal_period)\n",
    "    best_params_per_cluster[cluster_id] = best_params_cluster\n",
    "  return best_params_per_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y predicción\n",
    "\n",
    "Finalmente, juntamos todo lo anterior para realizar el entrenamiento y predicción para cada una de las series, aprovechando los parámetros obtenidos en esa gridsearch por cluster.\n",
    "Aquí tenemos un caso en el que el nivel de parametrización tratamos de llevarlo más avanzado, dando la posibilidad de aplicar incluso distintos algoritmos y parametrizaciones entre clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_append_from_predictions(predicted, ts_id):\n",
    "  week_1 = sum(predicted[:7])\n",
    "  week_2 = sum(predicted[7:])\n",
    "  days_week_consumptions = np.append(np.append(predicted[:7], week_1), week_2)\n",
    "  return np.concatenate(([ts_id],days_week_consumptions))\n",
    "  \n",
    "\n",
    "def train_predict_by_id(train_dataset, model_per_cluster, params_per_cluster, scaler_per_cluster, default_model, default_params, default_scaler, predict_steps=14):\n",
    "  column_names = ['id', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6', 'day_7', 'week_1', 'week_2']\n",
    "  df = pd.DataFrame(columns = column_names)\n",
    "  ids = set(train_dataset['id'])\n",
    "  for ts_id in ids:\n",
    "    try:\n",
    "      print('id: {id} de {len}, completado: {percent:.2f}%'.format(id=ts_id, len=len(ids), percent=(len(df)/len(ids))*100))\n",
    "      current_id_time_serie = train_dataset[train_dataset['id'] == ts_id]\n",
    "      cluster = list(current_id_time_serie['cluster'])[0]\n",
    "      print('Cluster:', cluster)\n",
    "\n",
    "      if cluster < UNCOMPLETE_SERIE_CLUSTER and model_per_cluster is not None:\n",
    "        params = params_per_cluster[cluster]\n",
    "        scaler = scaler_per_cluster[cluster]()\n",
    "        model = model_per_cluster[cluster](**params, scaler=scaler)\n",
    "      else:\n",
    "        scaler = default_scaler()\n",
    "        model = default_model(**default_params, scaler=scaler)\n",
    "\n",
    "      model.train(current_id_time_serie)\n",
    "      predicted = model.predict(predict_steps)\n",
    "      to_append = generate_append_from_predictions(predicted, ts_id)\n",
    "    \n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      to_append = [ts_id, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    df.loc[len(df)] = to_append\n",
    "  return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo de ejecución es el siguiente:\n",
    "1. Seleccionamos modelo, scaler y parámetros para las series que no tengan cluster (series incompletas)\n",
    "2. Creamos un diccionario para los parámetros de los modelos que queremos ejecutar para cada uno de los clusters\n",
    "3. Creamos un diccionario para los modelos que vamos a utilizar\n",
    "4. Seleccionamos los scalers que queremos probar.\n",
    "5. Ejecutamos el train-predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sarima_model import SarimaModel\n",
    "from models.autoreg_model import AutoregModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "default_sarima_params = {\n",
    "    'order': (1, 1, 1),\n",
    "    'seasonal_order': (1, 1, 1, 30),\n",
    "    'enforce_stationarity': False,\n",
    "    'enforce_invertibility': False\n",
    "}\n",
    "default_model = SarimaModel\n",
    "default_scaler = StandardScaler\n",
    "# params_by_cluster = grid_search_by_cluster(train_df)\n",
    "autoreg_params = {\n",
    "    'regressor': RandomForestRegressor\n",
    "}\n",
    "\n",
    "params_by_cluster = {\n",
    "    0: default_sarima_params,\n",
    "    1: autoreg_params,\n",
    "    2: autoreg_params,\n",
    "    3: autoreg_params,\n",
    "    4: autoreg_params,\n",
    "    5: autoreg_params,\n",
    "    6: autoreg_params,\n",
    "    7: autoreg_params,\n",
    "    8: autoreg_params,\n",
    "    9: autoreg_params,\n",
    "    10: autoreg_params\n",
    "}\n",
    "models_by_cluer = {\n",
    "    0: SarimaModel,\n",
    "    1: AutoregModel,\n",
    "    2: AutoregModel,\n",
    "    3: AutoregModel,\n",
    "    4: AutoregModel,\n",
    "    5: AutoregModel,\n",
    "    6: AutoregModel,\n",
    "    7: AutoregModel,\n",
    "    8: AutoregModel,\n",
    "    9: AutoregModel,\n",
    "    10: AutoregModel\n",
    "}\n",
    "scaler_by_cluster = {\n",
    "    0: StandardScaler,\n",
    "    1: StandardScaler,\n",
    "    2: StandardScaler,\n",
    "    3: StandardScaler,\n",
    "    4: StandardScaler,\n",
    "    5: StandardScaler,\n",
    "    6: StandardScaler,\n",
    "    7: StandardScaler,\n",
    "    8: StandardScaler,\n",
    "    9: StandardScaler,\n",
    "    10: StandardScaler\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0 de 101, completado: 0.00%\n",
      "Cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1 de 101, completado: 0.99%\n",
      "Cluster: 6\n",
      "id: 2 de 101, completado: 1.98%\n",
      "Cluster: 3\n",
      "id: 3 de 101, completado: 2.97%\n",
      "Cluster: 7\n",
      "id: 4 de 101, completado: 3.96%\n",
      "Cluster: 3\n",
      "id: 5 de 101, completado: 4.95%\n",
      "Cluster: 9\n",
      "id: 6 de 101, completado: 5.94%\n",
      "Cluster: 1\n",
      "id: 7 de 101, completado: 6.93%\n",
      "Cluster: 6\n",
      "id: 8 de 101, completado: 7.92%\n",
      "Cluster: 1\n",
      "id: 9 de 101, completado: 8.91%\n",
      "Cluster: 9\n",
      "id: 10 de 101, completado: 9.90%\n",
      "Cluster: 1\n",
      "id: 11 de 101, completado: 10.89%\n",
      "Cluster: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 12 de 101, completado: 11.88%\n",
      "Cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/numpy/lib/function_base.py:5438: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 13 de 101, completado: 12.87%\n",
      "Cluster: 0\n",
      "id: 14 de 101, completado: 13.86%\n",
      "Cluster: 5\n",
      "id: 15 de 101, completado: 14.85%\n",
      "Cluster: 1\n",
      "id: 16 de 101, completado: 15.84%\n",
      "Cluster: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 17 de 101, completado: 16.83%\n",
      "Cluster: 9\n",
      "id: 18 de 101, completado: 17.82%\n",
      "Cluster: 3\n",
      "id: 19 de 101, completado: 18.81%\n",
      "Cluster: 5\n",
      "id: 20 de 101, completado: 19.80%\n",
      "Cluster: 0\n",
      "id: 21 de 101, completado: 20.79%\n",
      "Cluster: 8\n",
      "id: 22 de 101, completado: 21.78%\n",
      "Cluster: 7\n",
      "id: 23 de 101, completado: 22.77%\n",
      "Cluster: 10\n",
      "id: 24 de 101, completado: 23.76%\n",
      "Cluster: 3\n",
      "id: 25 de 101, completado: 24.75%\n",
      "Cluster: 6\n",
      "id: 26 de 101, completado: 25.74%\n",
      "Cluster: 10\n",
      "id: 27 de 101, completado: 26.73%\n",
      "Cluster: 3\n",
      "id: 28 de 101, completado: 27.72%\n",
      "Cluster: 7\n",
      "id: 29 de 101, completado: 28.71%\n",
      "Cluster: 5\n",
      "id: 30 de 101, completado: 29.70%\n",
      "Cluster: 3\n",
      "id: 31 de 101, completado: 30.69%\n",
      "Cluster: 3\n",
      "id: 32 de 101, completado: 31.68%\n",
      "Cluster: 10\n",
      "id: 33 de 101, completado: 32.67%\n",
      "Cluster: 10\n",
      "id: 34 de 101, completado: 33.66%\n",
      "Cluster: 10\n",
      "id: 35 de 101, completado: 34.65%\n",
      "Cluster: 10\n",
      "id: 36 de 101, completado: 35.64%\n",
      "Cluster: 5\n",
      "id: 37 de 101, completado: 36.63%\n",
      "Cluster: 10\n",
      "id: 38 de 101, completado: 37.62%\n",
      "Cluster: 0\n",
      "id: 39 de 101, completado: 38.61%\n",
      "Cluster: 10\n",
      "id: 40 de 101, completado: 39.60%\n",
      "Cluster: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 41 de 101, completado: 40.59%\n",
      "Cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 42 de 101, completado: 41.58%\n",
      "Cluster: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 43 de 101, completado: 42.57%\n",
      "Cluster: 0\n",
      "id: 44 de 101, completado: 43.56%\n",
      "Cluster: 6\n",
      "id: 45 de 101, completado: 44.55%\n",
      "Cluster: 6\n",
      "id: 46 de 101, completado: 45.54%\n",
      "Cluster: 6\n",
      "id: 47 de 101, completado: 46.53%\n",
      "Cluster: 9\n",
      "id: 48 de 101, completado: 47.52%\n",
      "Cluster: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 49 de 101, completado: 48.51%\n",
      "Cluster: 4\n",
      "id: 50 de 101, completado: 49.50%\n",
      "Cluster: 7\n",
      "id: 51 de 101, completado: 50.50%\n",
      "Cluster: 1\n",
      "id: 52 de 101, completado: 51.49%\n",
      "Cluster: 5\n",
      "id: 53 de 101, completado: 52.48%\n",
      "Cluster: 5\n",
      "id: 54 de 101, completado: 53.47%\n",
      "Cluster: 10\n",
      "id: 55 de 101, completado: 54.46%\n",
      "Cluster: 9\n",
      "id: 56 de 101, completado: 55.45%\n",
      "Cluster: 1\n",
      "id: 57 de 101, completado: 56.44%\n",
      "Cluster: 9\n",
      "id: 58 de 101, completado: 57.43%\n",
      "Cluster: 2\n",
      "id: 59 de 101, completado: 58.42%\n",
      "Cluster: 0\n",
      "id: 60 de 101, completado: 59.41%\n",
      "Cluster: 1\n",
      "id: 61 de 101, completado: 60.40%\n",
      "Cluster: 6\n",
      "id: 62 de 101, completado: 61.39%\n",
      "Cluster: 10\n",
      "id: 63 de 101, completado: 62.38%\n",
      "Cluster: 7\n",
      "id: 64 de 101, completado: 63.37%\n",
      "Cluster: 10\n",
      "id: 65 de 101, completado: 64.36%\n",
      "Cluster: 5\n",
      "id: 66 de 101, completado: 65.35%\n",
      "Cluster: 0\n",
      "id: 67 de 101, completado: 66.34%\n",
      "Cluster: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 68 de 101, completado: 67.33%\n",
      "Cluster: 6\n",
      "id: 69 de 101, completado: 68.32%\n",
      "Cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 70 de 101, completado: 69.31%\n",
      "Cluster: 1\n",
      "id: 71 de 101, completado: 70.30%\n",
      "Cluster: 7\n",
      "id: 72 de 101, completado: 71.29%\n",
      "Cluster: 10\n",
      "id: 73 de 101, completado: 72.28%\n",
      "Cluster: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 74 de 101, completado: 73.27%\n",
      "Cluster: 10\n",
      "id: 75 de 101, completado: 74.26%\n",
      "Cluster: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 76 de 101, completado: 75.25%\n",
      "Cluster: 10\n",
      "id: 77 de 101, completado: 76.24%\n",
      "Cluster: 6\n",
      "id: 78 de 101, completado: 77.23%\n",
      "Cluster: 10\n",
      "id: 79 de 101, completado: 78.22%\n",
      "Cluster: 10\n",
      "id: 80 de 101, completado: 79.21%\n",
      "Cluster: 3\n",
      "id: 81 de 101, completado: 80.20%\n",
      "Cluster: 3\n",
      "id: 82 de 101, completado: 81.19%\n",
      "Cluster: 0\n",
      "id: 83 de 101, completado: 82.18%\n",
      "Cluster: 7\n",
      "id: 84 de 101, completado: 83.17%\n",
      "Cluster: 1\n",
      "id: 85 de 101, completado: 84.16%\n",
      "Cluster: 10\n",
      "id: 86 de 101, completado: 85.15%\n",
      "Cluster: 5\n",
      "id: 87 de 101, completado: 86.14%\n",
      "Cluster: 8\n",
      "id: 88 de 101, completado: 87.13%\n",
      "Cluster: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 89 de 101, completado: 88.12%\n",
      "Cluster: 0\n",
      "id: 90 de 101, completado: 89.11%\n",
      "Cluster: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cherra/PycharmProjects/medium-projects/tesla-analysis/.tesla-analysis-venv/lib/python3.8/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 91 de 101, completado: 90.10%\n",
      "Cluster: 6\n",
      "id: 92 de 101, completado: 91.09%\n",
      "Cluster: 9\n",
      "id: 93 de 101, completado: 92.08%\n",
      "Cluster: 9\n",
      "id: 94 de 101, completado: 93.07%\n",
      "Cluster: 5\n",
      "id: 95 de 101, completado: 94.06%\n",
      "Cluster: 0\n",
      "id: 96 de 101, completado: 95.05%\n",
      "Cluster: 3\n",
      "id: 97 de 101, completado: 96.04%\n",
      "Cluster: 5\n",
      "id: 98 de 101, completado: 97.03%\n",
      "Cluster: 0\n",
      "id: 99 de 101, completado: 98.02%\n",
      "Cluster: 0\n",
      "id: 100 de 101, completado: 99.01%\n",
      "Cluster: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "      <th>day_7</th>\n",
       "      <th>week_1</th>\n",
       "      <th>week_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>206.059388</td>\n",
       "      <td>210.640837</td>\n",
       "      <td>264.143792</td>\n",
       "      <td>299.997595</td>\n",
       "      <td>300.955687</td>\n",
       "      <td>290.741454</td>\n",
       "      <td>289.559851</td>\n",
       "      <td>1862.098603</td>\n",
       "      <td>2163.337914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.160929</td>\n",
       "      <td>12.063868</td>\n",
       "      <td>7.63359</td>\n",
       "      <td>1.941633</td>\n",
       "      <td>19.970671</td>\n",
       "      <td>1.521835</td>\n",
       "      <td>14.900836</td>\n",
       "      <td>79.193363</td>\n",
       "      <td>66.701848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>32.885974</td>\n",
       "      <td>43.688806</td>\n",
       "      <td>35.976781</td>\n",
       "      <td>41.782145</td>\n",
       "      <td>47.068645</td>\n",
       "      <td>39.298145</td>\n",
       "      <td>48.033811</td>\n",
       "      <td>288.734307</td>\n",
       "      <td>235.753442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>429.316801</td>\n",
       "      <td>428.404113</td>\n",
       "      <td>373.894761</td>\n",
       "      <td>505.58446</td>\n",
       "      <td>374.157953</td>\n",
       "      <td>426.993172</td>\n",
       "      <td>366.081909</td>\n",
       "      <td>2904.433169</td>\n",
       "      <td>3119.925257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>337.624208</td>\n",
       "      <td>310.405748</td>\n",
       "      <td>234.161892</td>\n",
       "      <td>272.962778</td>\n",
       "      <td>268.410692</td>\n",
       "      <td>284.032994</td>\n",
       "      <td>261.260375</td>\n",
       "      <td>1968.858688</td>\n",
       "      <td>1988.419842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       day_1       day_2       day_3       day_4       day_5  \\\n",
       "0  0.0  206.059388  210.640837  264.143792  299.997595  300.955687   \n",
       "1  1.0   21.160929   12.063868     7.63359    1.941633   19.970671   \n",
       "2  2.0   32.885974   43.688806   35.976781   41.782145   47.068645   \n",
       "3  3.0  429.316801  428.404113  373.894761   505.58446  374.157953   \n",
       "4  4.0  337.624208  310.405748  234.161892  272.962778  268.410692   \n",
       "\n",
       "        day_6       day_7       week_1       week_2  \n",
       "0  290.741454  289.559851  1862.098603  2163.337914  \n",
       "1    1.521835   14.900836    79.193363    66.701848  \n",
       "2   39.298145   48.033811   288.734307   235.753442  \n",
       "3  426.993172  366.081909  2904.433169  3119.925257  \n",
       "4  284.032994  261.260375  1968.858688  1988.419842  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = train_predict_by_id(train_df, None, None, None, default_model=default_model, default_params=default_sarima_params, default_scaler=default_scaler, predict_steps=14)\n",
    "predictions.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "Como en cualquier problema de ciencia de datos, debemos de establecer una metodología para evaluar la calidad de los resultados. En este caso lo primero que hacemos es con el conjunto de datos real de test, creamos un dataset igual al de predicción para poder compararlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_to_append(values):\n",
    "    if len(values) < 14:\n",
    "        to_append = [0] * (14-len(values))\n",
    "        values = np.append(to_append, values)\n",
    "    week_1 = sum(values[:7])\n",
    "    week_2 = sum(values[7:])\n",
    "    days_week_consumptions = np.append(np.append(values[:7], week_1), week_2)\n",
    "    return days_week_consumptions\n",
    "    \n",
    "\n",
    "\n",
    "def create_df_eval(test_df):\n",
    "\n",
    "    column_names = ['id', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6', 'day_7', 'week_1', 'week_2']\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "    ids = list(set(test_df['id']))\n",
    "    ids.sort()\n",
    "\n",
    "    for serie_id in ids:\n",
    "        time_serie = test_df[test_df['id'] == serie_id]\n",
    "        values = time_serie.sort_values(by=[\"datetime\"])[\"consumption\"].values\n",
    "        to_append = create_to_append(values)\n",
    "        row = [serie_id]\n",
    "        row.extend(to_append)\n",
    "        df.loc[len(df)] = row\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "      <th>day_7</th>\n",
       "      <th>week_1</th>\n",
       "      <th>week_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>271</td>\n",
       "      <td>306</td>\n",
       "      <td>292</td>\n",
       "      <td>460</td>\n",
       "      <td>331</td>\n",
       "      <td>368</td>\n",
       "      <td>2449</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>234</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>485</td>\n",
       "      <td>394</td>\n",
       "      <td>233</td>\n",
       "      <td>297</td>\n",
       "      <td>312</td>\n",
       "      <td>321</td>\n",
       "      <td>439</td>\n",
       "      <td>2481</td>\n",
       "      <td>2792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>362</td>\n",
       "      <td>387</td>\n",
       "      <td>359</td>\n",
       "      <td>289</td>\n",
       "      <td>286</td>\n",
       "      <td>361</td>\n",
       "      <td>202</td>\n",
       "      <td>2246</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  day_1  day_2  day_3  day_4  day_5  day_6  day_7  week_1  week_2\n",
       "0   0    421    271    306    292    460    331    368    2449    2222\n",
       "1   1      0    215     14      3      0      0      0     232      43\n",
       "2   2     28     33     48     35     33     20     37     234     272\n",
       "3   3    485    394    233    297    312    321    439    2481    2792\n",
       "4   4    362    387    359    289    286    361    202    2246    2194"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = create_df_eval(test_df)\n",
    "eval_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas y comparación de resultados\n",
    "\n",
    "Una vez tenemos el dataframe de predicción y el valor real, podemos evaluar distintas métricas.\n",
    "En nuestro problema la métrica que iban a utilizar para evaluarnos era una combinación de los **RMSE** de las distintas variables, nosotros para evaluar el desempeño de nuestros modelos podíamos hacer distintas comparaciones como por ejemplo un RMSE global o un RMSE por cada variable. \n",
    "Finalmente, es conveniente anotar el resultado de cada métrica en un excel, además de anotar los parámetro de la ejecución y cualquier cosa que queramos apuntar para hacerlo un **proceso replicable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_no_id = eval_df.drop(columns=['id'])\n",
    "predictions_no_id = predictions.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_by_column(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_column = rmse_by_column(eval_df_no_id, predictions_no_id)\n",
    "error_by_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_rmse(y_true, y_pred): \n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_df_no_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m error \u001b[39m=\u001b[39m total_rmse(eval_df_no_id, predictions_no_id)\n\u001b[1;32m      2\u001b[0m error\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_df_no_id' is not defined"
     ]
    }
   ],
   "source": [
    "error = total_rmse(eval_df_no_id, predictions_no_id)\n",
    "error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesla-analysis",
   "language": "python",
   "name": "tesla-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97904ca879a968c6e8bbdfccb264e127b174282fa9d008faaeaf032ab0be8c9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
